{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90733b49",
   "metadata": {},
   "source": [
    "# **09.Regularized Model-LASSO Code 실습**\n",
    "\n",
    "[목적]\n",
    "  1. LASSO\n",
    "    - Regularized Linear Model을 활용하여 Overfitting을 방지함\n",
    "    - Hyperparameter lamba를 튜닝할 때 for loop 뿐만 아니라 GridsearchCV를 통해 돌출해봄\n",
    "  3. Regularized Linear Models의 경우 X's Scaling을 필수적으로 진행해야함\n",
    "\n",
    "[Process]\n",
    "  1. Define X's & Y\n",
    "  2. Split Train & Valid dataset\n",
    "  3. Modeling\n",
    "  4. Model 해석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f54d0be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Sklearn Toy Data\n",
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "796932ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading (당뇨병)\n",
    "data = pd.read_csv('https://www4.stat.ncsu.edu/~boos/var.select/diabetes.tab.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f832dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X's & Y Split\n",
    "Y = data['Y']\n",
    "X = data.drop(columns=['Y'])\n",
    "X = pd.get_dummies(X, columns=['SEX'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bc1e2d",
   "metadata": {},
   "source": [
    "[Data Split]\n",
    "\n",
    "- Data Split을 진행할 때 BigData의 경우 꼭 indexing을 추출하여 모델에 적용시켜야 함\n",
    "- 이유는 Data Split하여 새로운 Data set을 만들 경우 메모리에 부담을 주기 때문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f3d677c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> # of Train data : 309\n",
      ">>>> # of valid data : 133\n"
     ]
    }
   ],
   "source": [
    "idx = list(range(X.shape[0]))\n",
    "train_idx, valid_idx = train_test_split(idx, test_size=0.3, random_state=2023)\n",
    "print(\">>>> # of Train data : {}\".format(len(train_idx)))\n",
    "print(\">>>> # of valid data : {}\".format(len(valid_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4960a476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "scaler = MinMaxScaler().fit(X.iloc[train_idx])\n",
    "X_scal = scaler.transform(X)\n",
    "X_scal = pd.DataFrame(X_scal, columns = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4411ebdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from sklearn import metrics\n",
    "\n",
    "def sse(clf, X, y):\n",
    "    \"\"\"Calculate the standard squared error of the model.\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The standard squared error of the model.\n",
    "    \"\"\"\n",
    "    y_hat = clf.predict(X)\n",
    "    sse = np.sum((y_hat - y) ** 2)\n",
    "    return sse / X.shape[0]\n",
    "\n",
    "\n",
    "def adj_r2_score(clf, X, y):\n",
    "    \"\"\"Calculate the adjusted :math:`R^2` of the model.\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The adjusted :math:`R^2` of the model.\n",
    "    \"\"\"\n",
    "    n = X.shape[0]  # Number of observations\n",
    "    p = X.shape[1]  # Number of features\n",
    "    r_squared = metrics.r2_score(y, clf.predict(X))\n",
    "    return 1 - (1 - r_squared) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "\n",
    "def coef_se(clf, X, y):\n",
    "    \"\"\"Calculate standard error for beta coefficients.\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        An array of standard errors for the beta coefficients.\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "    X1 = np.hstack((np.ones((n, 1)), np.matrix(X)))\n",
    "    se_matrix = scipy.linalg.sqrtm(\n",
    "        metrics.mean_squared_error(y, clf.predict(X)) *\n",
    "        np.linalg.inv(X1.T * X1)\n",
    "    )\n",
    "    return np.diagonal(se_matrix)\n",
    "\n",
    "\n",
    "def coef_tval(clf, X, y):\n",
    "    \"\"\"Calculate t-statistic for beta coefficients.\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        An array of t-statistic values.\n",
    "    \"\"\"\n",
    "    a = np.array(clf.intercept_ / coef_se(clf, X, y)[0])\n",
    "    b = np.array(clf.coef_ / coef_se(clf, X, y)[1:])\n",
    "    return np.append(a, b)\n",
    "\n",
    "\n",
    "def coef_pval(clf, X, y):\n",
    "    \"\"\"Calculate p-values for beta coefficients.\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        An array of p-values.\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "    t = coef_tval(clf, X, y)\n",
    "    p = 2 * (1 - scipy.stats.t.cdf(abs(t), n - 1))\n",
    "    return p\n",
    "\n",
    "def summary(clf, X, y, xlabels=None):\n",
    "    \"\"\"\n",
    "    Output summary statistics for a fitted regression model.\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "    xlabels : list, tuple\n",
    "        The labels for the predictors.\n",
    "    \"\"\"\n",
    "    # Check and/or make xlabels\n",
    "    ncols = X.shape[1]\n",
    "    if xlabels is None:\n",
    "        xlabels = np.array(\n",
    "            ['x{0}'.format(i) for i in range(1, ncols + 1)], dtype='str')\n",
    "    elif isinstance(xlabels, (tuple, list)):\n",
    "        xlabels = np.array(xlabels, dtype='str')\n",
    "    # Make sure dims of xlabels matches dims of X\n",
    "    if xlabels.shape[0] != ncols:\n",
    "        raise AssertionError(\n",
    "            \"Dimension of xlabels {0} does not match \"\n",
    "            \"X {1}.\".format(xlabels.shape, X.shape))\n",
    "    # Create data frame of coefficient estimates and associated stats\n",
    "    coef_df = pd.DataFrame(\n",
    "        index=['_intercept'] + list(xlabels),\n",
    "        columns=['Estimate', 'Std. Error', 't value', 'p value']\n",
    "    )\n",
    "    try:\n",
    "        coef_df['Estimate'] = np.concatenate(\n",
    "            (np.round(np.array([clf.intercept_]), 6), np.round((clf.coef_), 6)))\n",
    "    except Exception as e:\n",
    "        coef_df['Estimate'] = np.concatenate(\n",
    "            (\n",
    "                np.round(np.array([clf.intercept_]), 6),\n",
    "                np.round((clf.coef_), 6)\n",
    "            ), axis = 1\n",
    "    )[0,:]\n",
    "    coef_df['Std. Error'] = np.round(coef_se(clf, X, y), 6)\n",
    "    coef_df['t value'] = np.round(coef_tval(clf, X, y), 4)\n",
    "    coef_df['p value'] = np.round(coef_pval(clf, X, y), 6)\n",
    "    # Output results\n",
    "    print('Coefficients:')\n",
    "    print(coef_df.to_string(index=True))\n",
    "    print('---')\n",
    "    print('R-squared:  {0:.6f},    Adjusted R-squared:  {1:.6f},    MSE: {2:.1f}'.format(\n",
    "        metrics.r2_score(y, clf.predict(X)), adj_r2_score(clf, X, y), sse(clf, X, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cd8118",
   "metadata": {},
   "source": [
    "[LASSO Regression]\n",
    "\n",
    "  - Hyperparameter Tuning using for Loop\n",
    "  - Hyperparameter Tuning using GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7d368f",
   "metadata": {},
   "source": [
    "[LASSO Regression Parameters]\n",
    "  - Package : https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\n",
    "  - alpha : L1-norm Penalty Term\n",
    "    - alpha : 0 일 때, Just Linear Regression  \n",
    "  - fit_intercept : Centering to zero\n",
    "    - 베타0를 0로 보내는 것 (베타0는 상수이기 때문에)\n",
    "  - max_iter : Maximum number of interation\n",
    "    - Loss Function의 LASSO Penalty Term은 절대 값이기 때문에 Gradient Descent와 같은 최적화가 필요함\n",
    "    - Penalty Term : ||y - Xw||^2_2 + alpha * ||w||_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a425993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha : 0.0000001, R2:0.5301651, MSE:3084.6122329, RMSE:55.5392855\n",
      "Alpha : 0.0000005, R2:0.5301651, MSE:3084.6121132, RMSE:55.5392844\n",
      "Alpha : 0.0000010, R2:0.5301652, MSE:3084.6119624, RMSE:55.5392831\n",
      "Alpha : 0.0000050, R2:0.5301653, MSE:3084.6107549, RMSE:55.5392722\n",
      "Alpha : 0.0000100, R2:0.5301656, MSE:3084.6092464, RMSE:55.5392586\n",
      "Alpha : 0.0000500, R2:0.5301674, MSE:3084.5972157, RMSE:55.5391503\n",
      "Alpha : 0.0001000, R2:0.5301697, MSE:3084.5822667, RMSE:55.5390157\n",
      "Alpha : 0.0010000, R2:0.5302081, MSE:3084.3301897, RMSE:55.5367463\n",
      "Alpha : 0.0100000, R2:0.5304264, MSE:3082.8971348, RMSE:55.5238429\n",
      "Alpha : 0.0200000, R2:0.5306024, MSE:3081.7414647, RMSE:55.5134350\n",
      "Alpha : 0.0300000, R2:0.5304378, MSE:3082.8220339, RMSE:55.5231666\n",
      "Alpha : 0.0400000, R2:0.5300232, MSE:3085.5438451, RMSE:55.5476718\n"
     ]
    }
   ],
   "source": [
    "penalty = [0.0000001, 0.0000005, 0.000001, 0.000005, 0.00001, 0.00005, 0.0001, 0.001, 0.01, 0.02, 0.03, 0.04]\n",
    "\n",
    "# LASSO Regression\n",
    "# select alpha by checking R2, MSE, RMSE\n",
    "\n",
    "for a in penalty:\n",
    "    model = Lasso(alpha=a).fit(X_scal.iloc[train_idx], Y.iloc[train_idx])\n",
    "    score = model.score(X_scal.iloc[valid_idx], Y.iloc[valid_idx])\n",
    "    pred_y = model.predict(X_scal.iloc[valid_idx])\n",
    "    mse = mean_squared_error(Y.iloc[valid_idx], pred_y)\n",
    "    print(\"Alpha : {0:.7f}, R2:{1:.7f}, MSE:{2:.7f}, RMSE:{3:.7f}\".format(a, score, mse, np.sqrt(mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077fd006",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
