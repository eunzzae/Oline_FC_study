{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43344e61",
   "metadata": {},
   "source": [
    "# **09.Regularized Model-LASSO Code 실습**\n",
    "\n",
    "[목적]\n",
    "  1. LASSO\n",
    "    - Regularized Linear Model을 활용하여 Overfitting을 방지함\n",
    "    - Hyperparameter lamba를 튜닝할 때 for loop 뿐만 아니라 GridsearchCV를 통해 돌출해봄\n",
    "  3. Regularized Linear Models의 경우 X's Scaling을 필수적으로 진행해야함\n",
    "\n",
    "[Process]\n",
    "  1. Define X's & Y\n",
    "  2. Split Train & Valid dataset\n",
    "  3. Modeling\n",
    "  4. Model 해석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "333bbce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Sklearn Toy Data\n",
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3d32a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading (당뇨병)\n",
    "data = pd.read_csv('https://www4.stat.ncsu.edu/~boos/var.select/diabetes.tab.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b92be35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X's & Y Split\n",
    "Y = data['Y']\n",
    "X = data.drop(columns=['Y'])\n",
    "X = pd.get_dummies(X, columns=['SEX'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d168f3f7",
   "metadata": {},
   "source": [
    "[Data Split]\n",
    "\n",
    "- Data Split을 진행할 때 BigData의 경우 꼭 indexing을 추출하여 모델에 적용시켜야 함\n",
    "- 이유는 Data Split하여 새로운 Data set을 만들 경우 메모리에 부담을 주기 때문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7535f0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> # of Train data : 309\n",
      ">>>> # of valid data : 133\n"
     ]
    }
   ],
   "source": [
    "idx = list(range(X.shape[0]))\n",
    "train_idx, valid_idx = train_test_split(idx, test_size=0.3, random_state=2023)\n",
    "print(\">>>> # of Train data : {}\".format(len(train_idx)))\n",
    "print(\">>>> # of valid data : {}\".format(len(valid_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9419080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "scaler = MinMaxScaler().fit(X.iloc[train_idx])\n",
    "X_scal = scaler.transform(X)\n",
    "X_scal = pd.DataFrame(X_scal, columns = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f4ce5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from sklearn import metrics\n",
    "\n",
    "def sse(clf, X, y):\n",
    "    \"\"\"Calculate the standard squared error of the model.\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The standard squared error of the model.\n",
    "    \"\"\"\n",
    "    y_hat = clf.predict(X)\n",
    "    sse = np.sum((y_hat - y) ** 2)\n",
    "    return sse / X.shape[0]\n",
    "\n",
    "\n",
    "def adj_r2_score(clf, X, y):\n",
    "    \"\"\"Calculate the adjusted :math:`R^2` of the model.\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The adjusted :math:`R^2` of the model.\n",
    "    \"\"\"\n",
    "    n = X.shape[0]  # Number of observations\n",
    "    p = X.shape[1]  # Number of features\n",
    "    r_squared = metrics.r2_score(y, clf.predict(X))\n",
    "    return 1 - (1 - r_squared) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "\n",
    "def coef_se(clf, X, y):\n",
    "    \"\"\"Calculate standard error for beta coefficients.\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        An array of standard errors for the beta coefficients.\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "    X1 = np.hstack((np.ones((n, 1)), np.matrix(X)))\n",
    "    se_matrix = scipy.linalg.sqrtm(\n",
    "        metrics.mean_squared_error(y, clf.predict(X)) *\n",
    "        np.linalg.inv(X1.T * X1)\n",
    "    )\n",
    "    return np.diagonal(se_matrix)\n",
    "\n",
    "\n",
    "def coef_tval(clf, X, y):\n",
    "    \"\"\"Calculate t-statistic for beta coefficients.\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        An array of t-statistic values.\n",
    "    \"\"\"\n",
    "    a = np.array(clf.intercept_ / coef_se(clf, X, y)[0])\n",
    "    b = np.array(clf.coef_ / coef_se(clf, X, y)[1:])\n",
    "    return np.append(a, b)\n",
    "\n",
    "\n",
    "def coef_pval(clf, X, y):\n",
    "    \"\"\"Calculate p-values for beta coefficients.\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        An array of p-values.\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "    t = coef_tval(clf, X, y)\n",
    "    p = 2 * (1 - scipy.stats.t.cdf(abs(t), n - 1))\n",
    "    return p\n",
    "\n",
    "def summary(clf, X, y, xlabels=None):\n",
    "    \"\"\"\n",
    "    Output summary statistics for a fitted regression model.\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "    xlabels : list, tuple\n",
    "        The labels for the predictors.\n",
    "    \"\"\"\n",
    "    # Check and/or make xlabels\n",
    "    ncols = X.shape[1]\n",
    "    if xlabels is None:\n",
    "        xlabels = np.array(\n",
    "            ['x{0}'.format(i) for i in range(1, ncols + 1)], dtype='str')\n",
    "    elif isinstance(xlabels, (tuple, list)):\n",
    "        xlabels = np.array(xlabels, dtype='str')\n",
    "    # Make sure dims of xlabels matches dims of X\n",
    "    if xlabels.shape[0] != ncols:\n",
    "        raise AssertionError(\n",
    "            \"Dimension of xlabels {0} does not match \"\n",
    "            \"X {1}.\".format(xlabels.shape, X.shape))\n",
    "    # Create data frame of coefficient estimates and associated stats\n",
    "    coef_df = pd.DataFrame(\n",
    "        index=['_intercept'] + list(xlabels),\n",
    "        columns=['Estimate', 'Std. Error', 't value', 'p value']\n",
    "    )\n",
    "    try:\n",
    "        coef_df['Estimate'] = np.concatenate(\n",
    "            (np.round(np.array([clf.intercept_]), 6), np.round((clf.coef_), 6)))\n",
    "    except Exception as e:\n",
    "        coef_df['Estimate'] = np.concatenate(\n",
    "            (\n",
    "                np.round(np.array([clf.intercept_]), 6),\n",
    "                np.round((clf.coef_), 6)\n",
    "            ), axis = 1\n",
    "    )[0,:]\n",
    "    coef_df['Std. Error'] = np.round(coef_se(clf, X, y), 6)\n",
    "    coef_df['t value'] = np.round(coef_tval(clf, X, y), 4)\n",
    "    coef_df['p value'] = np.round(coef_pval(clf, X, y), 6)\n",
    "    # Output results\n",
    "    print('Coefficients:')\n",
    "    print(coef_df.to_string(index=True))\n",
    "    print('---')\n",
    "    print('R-squared:  {0:.6f},    Adjusted R-squared:  {1:.6f},    MSE: {2:.1f}'.format(\n",
    "        metrics.r2_score(y, clf.predict(X)), adj_r2_score(clf, X, y), sse(clf, X, y)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
